{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating Message Passing Networks**\n",
    "- Generalizing the convolution operator to irregular domains is typically expressed as a neighborhood aggregation or message passing scheme. \n",
    "- torch_geometric.nn.MessagePassing : base class, which helps in **creating such kinds of message passing graph neural networks** by automatically taking care of **message propagation**.\n",
    "- The user only has to define **the functions ϕ , i.e. message()**, and **γ , .i.e. update()**, as well as the **aggregation scheme** to use, **.i.e. aggr='add', aggr='mean' or aggr='max'**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementing the GCN Layer**\n",
    "- Add self-loops to the adjacency matrix.\n",
    "- Linearly transform node feature matrix.\n",
    "- Compute normalization coefficients.\n",
    "- Normalize node features in ϕ.\n",
    "- Sum up neighboring node features (\"add\" aggregation).\n",
    "- Return new node embeddings in γ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNConv(\n",
      "  (lin): Linear(in_features=16, out_features=32, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-6: Start propagating messages.\n",
    "        return self.propagate(edge_index, \n",
    "                              size=(x.size(0), x.size(0)), \n",
    "                              x=x,\n",
    "                              norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # Step 6: Return new node embeddings.\n",
    "        return aggr_out\n",
    "    \n",
    "conv = GCNConv(16, 32)\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementing the Edge Convolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeConv, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "        return self.mlp(tmp)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "        return aggr_out            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "# 동적 Edge Convolution이란 아마도 point cloud 같은 점(노드)만 존재하는 상태에 대하여 edge를 정의하기위해\n",
    "# k-NN같은 알고리즘을 추가적으로 적용하는 방식을 '동적'이라고 표현한 것 같음 \n",
    "class DynamicEdgeConv(EdgeConv):\n",
    "    def __init__(self, in_channels, out_channels, k=6):\n",
    "        super(DynamicEdgeConv, self).__init__(in_channels, out_channels)\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x, batch=None):\n",
    "        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n",
    "        return super(DynamicEdgeConv, self).forward(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicEdgeConv(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv = DynamicEdgeConv(3, 128, k=6)\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
